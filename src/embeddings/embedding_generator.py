"""
Embedding generator for BCG Multi-Agent & Multimodal AI Platform.
"""
import logging
import os
from typing import Dict, List, Optional, Union

import numpy as np
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain_core.embeddings import Embeddings

logger = logging.getLogger(__name__)

class EmbeddingGenerator:
    """
    Generates embeddings for text using various embedding models.
    
    This class provides a unified interface for generating embeddings using 
    different embedding models, including local models (Sentence Transformers)
    and remote models (OpenAI).
    """
    
    def __init__(
        self,
        model_name: str = "all-MiniLM-L6-v2",
        model_type: str = "local",
        openai_api_key: Optional[str] = None,
        cache_folder: Optional[str] = None,
    ):
        """
        Initialize the embedding generator.
        
        Args:
            model_name: Name of the embedding model to use.
            model_type: Type of embedding model ('local' or 'openai').
            openai_api_key: OpenAI API key (required for 'openai' model_type).
            cache_folder: Optional folder to cache embeddings models.
        """
        self.model_name = model_name
        self.model_type = model_type.lower()
        
        if self.model_type == "openai":
            # Use OpenAI embeddings
            if not openai_api_key and not os.getenv("OPENAI_API_KEY"):
                raise ValueError("OpenAI API key is required for OpenAI embeddings")
            
            logger.info(f"Initializing OpenAI embeddings with model: {model_name}")
            self.embeddings = OpenAIEmbeddings(
                model=model_name,
                openai_api_key=openai_api_key or os.getenv("OPENAI_API_KEY"),
            )
        elif self.model_type == "local":
            # Use local Sentence Transformers model
            logger.info(f"Initializing Sentence Transformers embeddings with model: {model_name}")
            model_kwargs = {"device": "cpu"}
            
            if cache_folder:
                model_kwargs["cache_folder"] = cache_folder
                
            self.embeddings = HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs=model_kwargs,
            )
        else:
            raise ValueError(f"Unsupported model type: {model_type}. Choose 'local' or 'openai'.")
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        Generate an embedding for a single text.
        
        Args:
            text: The text to generate an embedding for.
            
        Returns:
            The embedding as a list of floats.
        """
        try:
            embedding = self.embeddings.embed_query(text)
            return embedding
        except Exception as e:
            logger.error(f"Error generating embedding: {str(e)}")
            raise
    
    def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Generate embeddings for multiple texts.
        
        Args:
            texts: The texts to generate embeddings for.
            
        Returns:
            List of embeddings, each as a list of floats.
        """
        try:
            embeddings = self.embeddings.embed_documents(texts)
            return embeddings
        except Exception as e:
            logger.error(f"Error generating embeddings: {str(e)}")
            raise
    
    def get_embedding_dimension(self) -> int:
        """
        Get the dimension of the embeddings.
        
        Returns:
            The dimension of the embeddings generated by this model.
        """
        # Generate a simple embedding to determine dimension
        sample_embedding = self.generate_embedding("Sample text for dimension checking")
        return len(sample_embedding)
    
    def get_embedding_model(self) -> Embeddings:
        """
        Get the underlying embedding model.
        
        Returns:
            The langchain Embeddings object.
        """
        return self.embeddings