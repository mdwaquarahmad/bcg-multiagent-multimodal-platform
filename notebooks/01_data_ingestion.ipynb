{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCG Multi-Agent & Multimodal AI Platform - Data Ingestion\n",
    "\n",
    "This notebook demonstrates the data ingestion process for BCG Sustainability Reports, including:\n",
    "1. PDF text extraction\n",
    "2. Visual element detection (charts, graphs)\n",
    "3. Document processing and structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from configs.config import (\n",
    "    RAW_DATA_DIR,\n",
    "    PROCESSED_DATA_DIR,\n",
    "    CHUNK_SIZE,\n",
    "    CHUNK_OVERLAP,\n",
    "    USE_OCR,\n",
    "    EXTRACT_CHARTS,\n",
    ")\n",
    "\n",
    "# Ensure the raw data directory exists\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Raw data directory: {RAW_DATA_DIR}\")\n",
    "print(f\"Processed data directory: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"Text chunk size: {CHUNK_SIZE}, overlap: {CHUNK_OVERLAP}\")\n",
    "print(f\"OCR enabled: {USE_OCR}\")\n",
    "print(f\"Chart extraction enabled: {EXTRACT_CHARTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload or Locate BCG Sustainability Reports\n",
    "\n",
    "For this demo, we need to ensure the BCG Sustainability Reports are in the `data/raw` directory. You can upload them or verify their presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# List available PDF files in the raw data directory\n",
    "pdf_files = list(RAW_DATA_DIR.glob(\"*.pdf\"))\n",
    "\n",
    "if len(pdf_files) == 0:\n",
    "    print(\"No PDF files found in the raw data directory.\")\n",
    "    print(f\"Please upload BCG Sustainability Reports to {RAW_DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\" - {pdf_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test PDF Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.data_ingestion.text_extraction.pdf_extractor import PDFTextExtractor\n",
    "\n",
    "# Initialize the PDF text extractor\n",
    "text_extractor = PDFTextExtractor(\n",
    "    use_unstructured=True,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    ")\n",
    "\n",
    "# Test text extraction on the first PDF (if available)\n",
    "if len(pdf_files) > 0:\n",
    "    test_pdf = pdf_files[0]\n",
    "    print(f\"Testing text extraction on {test_pdf.name}\")\n",
    "    \n",
    "    # Get metadata\n",
    "    metadata = text_extractor.get_document_metadata(test_pdf)\n",
    "    print(\"\\nDocument Metadata:\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\" - {key}: {value}\")\n",
    "    \n",
    "    # Extract and chunk text\n",
    "    chunks = text_extractor.extract_and_chunk_text(test_pdf)\n",
    "    print(f\"\\nExtracted {len(chunks)} text chunks\")\n",
    "    \n",
    "    # Display the first chunk\n",
    "    if chunks:\n",
    "        print(\"\\nSample text chunk:\")\n",
    "        print(chunks[0][:500] + \"...\")\n",
    "else:\n",
    "    print(\"No PDF files available for testing text extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Chart Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.data_ingestion.visual_extraction.chart_detector import ChartDetector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the chart detector\n",
    "chart_detector = ChartDetector(confidence_threshold=0.5)  # Lower threshold for demo\n",
    "\n",
    "# Test chart detection on the first PDF (if available)\n",
    "if len(pdf_files) > 0:\n",
    "    test_pdf = pdf_files[0]\n",
    "    print(f\"Testing chart detection on {test_pdf.name}\")\n",
    "    \n",
    "    # Detect charts\n",
    "    visual_elements = chart_detector.detect_charts(test_pdf)\n",
    "    print(f\"\\nDetected {len(visual_elements)} potential visual elements\")\n",
    "    \n",
    "    # Display the first few visual elements\n",
    "    max_display = min(3, len(visual_elements))\n",
    "    if visual_elements:\n",
    "        plt.figure(figsize=(15, 5 * max_display))\n",
    "        for i, element in enumerate(visual_elements[:max_display]):\n",
    "            plt.subplot(max_display, 1, i + 1)\n",
    "            plt.imshow(element.image)\n",
    "            plt.title(f\"{element.element_type} on page {element.page_num} (confidence: {element.confidence_score:.2f})\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No PDF files available for testing chart detection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from src.data_ingestion.document_processor import DocumentProcessor\n",
    "\n",
    "# Initialize the document processor\n",
    "document_processor = DocumentProcessor(\n",
    "    use_unstructured=True,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    extract_visuals=True,\n",
    "    confidence_threshold=0.5,  # Lower threshold for demo\n",
    ")\n",
    "\n",
    "# Process the first PDF (if available)\n",
    "if len(pdf_files) > 0:\n",
    "    test_pdf = pdf_files[0]\n",
    "    print(f\"Processing document: {test_pdf.name}\")\n",
    "    \n",
    "    # Process the document\n",
    "    processed_doc = document_processor.process_document(\n",
    "        pdf_path=test_pdf,\n",
    "        output_dir=PROCESSED_DATA_DIR,\n",
    "        save_visuals=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nProcessed document: {processed_doc.document_id}\")\n",
    "    print(f\"Text chunks: {len(processed_doc.text_chunks)}\")\n",
    "    print(f\"Visual elements: {len(processed_doc.visual_elements)}\")\n",
    "    print(\"\\nMetadata:\")\n",
    "    for key, value in processed_doc.metadata.items():\n",
    "        print(f\" - {key}: {value}\")\n",
    "else:\n",
    "    print(\"No PDF files available for document processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process All BCG Sustainability Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process all PDF files in the raw data directory\n",
    "if len(pdf_files) > 0:\n",
    "    print(f\"Processing all {len(pdf_files)} PDF files...\")\n",
    "    processed_docs = document_processor.process_directory(\n",
    "        input_dir=RAW_DATA_DIR,\n",
    "        output_dir=PROCESSED_DATA_DIR,\n",
    "        file_pattern=\"*.pdf\",\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed {len(processed_docs)} documents:\")\n",
    "    for doc in processed_docs:\n",
    "        print(f\" - {doc.filename}: {len(doc.text_chunks)} chunks, {len(doc.visual_elements)} visual elements\")\n",
    "else:\n",
    "    print(\"No PDF files available for processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Explore Processed Document Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "# Explore the content of processed documents (if available)\n",
    "processed_dirs = [d for d in PROCESSED_DATA_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "if processed_dirs:\n",
    "    # Select a random processed document\n",
    "    sample_doc_dir = random.choice(processed_dirs)\n",
    "    json_file = list(sample_doc_dir.glob(\"*.json\"))\n",
    "    \n",
    "    if json_file:\n",
    "        import json\n",
    "        \n",
    "        with open(json_file[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            doc_data = json.load(f)\n",
    "        \n",
    "        print(f\"Exploring document: {doc_data['filename']}\")\n",
    "        print(f\"Document ID: {doc_data['document_id']}\")\n",
    "        print(f\"Total text chunks: {len(doc_data['text_chunks'])}\")\n",
    "        print(f\"Total visual elements: {len(doc_data['visual_elements'])}\")\n",
    "        \n",
    "        # Display a random text chunk\n",
    "        if doc_data['text_chunks']:\n",
    "            sample_chunk = random.choice(doc_data['text_chunks'])\n",
    "            print(\"\\nSample text chunk:\")\n",
    "            print(sample_chunk[:500] + \"...\" if len(sample_chunk) > 500 else sample_chunk)\n",
    "        \n",
    "        # Display information about visual elements\n",
    "        if doc_data['visual_elements']:\n",
    "            print(\"\\nVisual elements:\")\n",
    "            for i, element in enumerate(doc_data['visual_elements']):\n",
    "                print(f\" - Element {i+1}: {element['element_type']} on page {element['page_num']} (confidence: {element['confidence_score']:.2f})\")\n",
    "                \n",
    "            # Load and display a sample visual element if available\n",
    "            visuals_dir = sample_doc_dir / \"visuals\"\n",
    "            if visuals_dir.exists():\n",
    "                visual_files = list(visuals_dir.glob(\"*.png\"))\n",
    "                if visual_files:\n",
    "                    sample_visual = random.choice(visual_files)\n",
    "                    print(f\"\\nDisplaying sample visual element: {sample_visual.name}\")\n",
    "                    \n",
    "                    from PIL import Image\n",
    "                    plt.figure(figsize=(10, 8))\n",
    "                    plt.imshow(Image.open(sample_visual))\n",
    "                    plt.axis('off')\n",
    "                    plt.title(sample_visual.name)\n",
    "                    plt.show()\n",
    "else:\n",
    "    print(\"No processed documents available for exploration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyzing Extracted Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Analyze the content of all processed documents (if available)\n",
    "processed_dirs = [d for d in PROCESSED_DATA_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "if processed_dirs:\n",
    "    # Collect data from all processed documents\n",
    "    all_chunks = []\n",
    "    doc_info = []\n",
    "    \n",
    "    for doc_dir in processed_dirs:\n",
    "        json_files = list(doc_dir.glob(\"*.json\"))\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                    doc_data = json.load(f)\n",
    "                \n",
    "                # Add document info\n",
    "                doc_info.append({\n",
    "                    \"document_id\": doc_data[\"document_id\"],\n",
    "                    \"filename\": doc_data[\"filename\"],\n",
    "                    \"chunks\": len(doc_data[\"text_chunks\"]),\n",
    "                    \"visuals\": len(doc_data[\"visual_elements\"]),\n",
    "                    \"pages\": doc_data[\"metadata\"].get(\"page_count\", \"N/A\"),\n",
    "                })\n",
    "                \n",
    "                # Add text chunks\n",
    "                for chunk in doc_data[\"text_chunks\"]:\n",
    "                    all_chunks.append({\n",
    "                        \"document_id\": doc_data[\"document_id\"],\n",
    "                        \"text\": chunk,\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {json_file}: {str(e)}\")\n",
    "    \n",
    "    # Create dataframes\n",
    "    doc_df = pd.DataFrame(doc_info)\n",
    "    chunks_df = pd.DataFrame(all_chunks)\n",
    "    \n",
    "    # Display document summary\n",
    "    print(\"Document Summary:\")\n",
    "    print(doc_df)\n",
    "    \n",
    "    # Analyze text content\n",
    "    if not chunks_df.empty:\n",
    "        # Extract key sustainability terms\n",
    "        sustainability_terms = [\n",
    "            \"sustainability\", \"climate\", \"carbon\", \"emission\", \"green\",\n",
    "            \"renewable\", \"environment\", \"social\", \"governance\", \"esg\",\n",
    "            \"net zero\", \"diversity\", \"inclusion\", \"ethical\", \"responsibility\"\n",
    "        ]\n",
    "        \n",
    "        # Count occurrences of each term\n",
    "        term_counts = {}\n",
    "        for term in sustainability_terms:\n",
    "            pattern = re.compile(r'\\b' + re.escape(term) + r'\\w*\\b', re.IGNORECASE)\n",
    "            count = sum(chunks_df[\"text\"].str.count(pattern))\n",
    "            term_counts[term] = count\n",
    "        \n",
    "        # Plot term frequencies\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        pd.Series(term_counts).sort_values(ascending=False).plot(kind=\"bar\")\n",
    "        plt.title(\"Frequency of Key Sustainability Terms\")\n",
    "        plt.xlabel(\"Term\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No processed documents available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've successfully demonstrated the data ingestion pipeline for the BCG Multi-Agent & Multimodal AI Platform. We've processed BCG Sustainability Reports, extracting both textual content and visual elements, and structured the data for further use in our RAG system.\n",
    "\n",
    "Next steps include:\n",
    "1. Creating embeddings for the extracted text chunks\n",
    "2. Building the vector database for retrieval\n",
    "3. Implementing the RAG components\n",
    "4. Developing the multi-agent system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}